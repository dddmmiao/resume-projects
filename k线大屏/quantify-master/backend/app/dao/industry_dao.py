"""è¡Œä¸šæ•°æ®è®¿é—®å±‚ (DAO) - SQLModelä¼˜åŒ–ç‰ˆæœ¬
è´Ÿè´£è¡Œä¸šæ¿å—åŠç›¸å…³å…³è”æ•°æ®çš„æ•°æ®åº“æ“ä½œï¼Œæä¾›é«˜æ€§èƒ½çš„æŸ¥è¯¢å’Œæ‰¹é‡æ“ä½œ
"""

from typing import List, Dict, Any, Optional

from loguru import logger
from sqlmodel import select, func, case

from app.constants.table_types import TableTypes
from app.models import db_session_context, TableFactory
from .dao_config import DAOConfig
from .query_utils import query_utils, QueryUtils
from .utils.batch_operations import batch_operations
from ..models import Industry, StockIndustry


class IndustryDAO:
    """è¡Œä¸šæ•°æ®è®¿é—®å±‚"""

    @staticmethod
    def _apply_filter_conditions(
        subq,
        filters: Optional[Dict[str, Any]],
        search: Optional[str],
        search_fields: Optional[List[str]],
        model,
    ):
        """åº”ç”¨ç­›é€‰å’Œæœç´¢æ¡ä»¶åˆ°å­æŸ¥è¯¢ã€‚"""
        from sqlalchemy import or_
        
        if filters:
            for field_name, value in filters.items():
                if hasattr(model, field_name):
                    field = getattr(model, field_name)
                    if isinstance(value, list):
                        subq = subq.where(field.in_(value))
                    else:
                        subq = subq.where(field == value)
        
        if search and search_fields:
            search_conditions = []
            for field_name in search_fields:
                if hasattr(model, field_name):
                    field = getattr(model, field_name)
                    search_conditions.append(field.like(f"%{search}%"))
            if search_conditions:
                subq = subq.where(or_(*search_conditions))
        
        return subq

    # ==================== è¡Œä¸šæ¿å—åŸºç¡€æ“ä½œ ====================

    @staticmethod
    def bulk_upsert_industry_data(
            data: List[Dict[str, Any]],
            batch_size: Optional[int] = None,
    ) -> Dict[str, int]:
        """
        æ‰¹é‡æ’å…¥æˆ–æ›´æ–°è¡Œä¸šæ¿å—æ•°æ®
        
        Args:
            data: è¦å¤„ç†çš„æ•°æ®åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            {"inserted_count": int, "updated_count": int}
        """
        # bulk_upsert_mysql_generated å†…éƒ¨å·²ç®¡ç†æ•°æ®åº“ä¼šè¯å’Œäº‹åŠ¡
        stats = batch_operations.bulk_upsert_mysql_generated(
            table_model=Industry,
            data=data,
            batch_size=batch_size or DAOConfig.DEFAULT_BATCH_SIZE,
        )
        return DAOConfig.format_upsert_result(stats)

    # ==================== è‚¡ç¥¨è¡Œä¸šå…³è” ====================

    @staticmethod
    def bulk_upsert_stock_industry_data(
            data: List[Dict[str, Any]],
            batch_size: Optional[int] = None
    ) -> Dict[str, int]:
        """
        æ‰¹é‡æ’å…¥æˆ–æ›´æ–°è‚¡ç¥¨è¡Œä¸šå…³è”æ•°æ®
        
        Args:
            data: è¦å¤„ç†çš„æ•°æ®åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            {"inserted_count": int, "updated_count": int, "total_count": int}
        """
        # bulk_upsert_mysql_generated å†…éƒ¨å·²ç®¡ç†æ•°æ®åº“ä¼šè¯å’Œäº‹åŠ¡
        stats = batch_operations.bulk_upsert_mysql_generated(
            table_model=StockIndustry,
            data=data,
            batch_size=batch_size or DAOConfig.DEFAULT_BATCH_SIZE,
        )
        return DAOConfig.format_upsert_result(stats)

    @staticmethod
    def load_stock_industries(
            ts_code: str
    ) -> List[str]:
        """
        ä»æ•°æ®åº“åŠ è½½è‚¡ç¥¨çš„è¡Œä¸šå…³è”ï¼ˆè¿”å›è¡Œä¸šåç§°æ•°ç»„ï¼‰
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è¡Œä¸šåç§°åˆ—è¡¨
        """
        try:
            # ğŸš€ SQLModelä¼˜åŒ–ï¼šä½¿ç”¨JOINæŸ¥è¯¢è·å–è¡Œä¸šåç§°è€Œä¸æ˜¯ä»£ç 
            with db_session_context() as db:
                stmt = select(Industry.industry_name).join(
                    StockIndustry, Industry.industry_code == StockIndustry.industry_code
                ).where(
                    StockIndustry.ts_code == ts_code
                )
                result = db.exec(stmt).all()
                return list(result)
        except Exception as e:
            logger.warning(f"åŠ è½½è‚¡ç¥¨è¡Œä¸šå…³è”å¤±è´¥ ({ts_code}): {e}")
            return []

    @staticmethod
    def get_ts_codes_by_industry_codes(industry_codes: List[str]) -> List[str]:
        """
        æ ¹æ®è¡Œä¸šä»£ç é›†åˆè·å–å…³è”çš„è‚¡ç¥¨ ts_code åˆ—è¡¨
        """
        if not industry_codes:
            return []
        try:
            # ğŸš€ SQLModelä¼˜åŒ–ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’ŒselectæŸ¥è¯¢
            with db_session_context() as db:
                stmt = select(StockIndustry.ts_code).where(
                    StockIndustry.industry_code.in_(industry_codes)
                ).distinct()
                result = db.exec(stmt).all()
                return list(result)
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢è¡Œä¸šå…³è”è‚¡ç¥¨å¤±è´¥: {e}")
            return []

    @staticmethod
    def get_industry_codes_by_stock_codes(stock_codes: List[str]) -> List[str]:
        """
        æ ¹æ®è‚¡ç¥¨ä»£ç é›†åˆè·å–å…³è”çš„è¡Œä¸šä»£ç åˆ—è¡¨
        """
        if not stock_codes:
            return []
        try:
            # ğŸš€ SQLModelä¼˜åŒ–ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’ŒselectæŸ¥è¯¢
            with db_session_context() as db:
                stmt = select(StockIndustry.industry_code).where(
                    StockIndustry.ts_code.in_(stock_codes)
                ).distinct()
                result = db.exec(stmt).all()
                return [code for code in result if code]
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢è‚¡ç¥¨å…³è”è¡Œä¸šå¤±è´¥: {e}")
            return []

    # ==================== ç»Ÿè®¡æ–¹æ³• ====================

    @staticmethod
    def get_industries(
            search: Optional[str] = None,
            search_fields: Optional[List[str]] = None,
            limit: Optional[int] = None,
            offset: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–è¡Œä¸šåˆ—è¡¨ï¼ˆæ”¯æŒæœç´¢ã€åˆ†é¡µï¼‰
        
        Args:
            search: æœç´¢å…³é”®è¯
            search_fields: æœç´¢å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤["industry_name"]
            limit: é™åˆ¶æ•°é‡
            offset: åç§»é‡
            
        Returns:
            è¡Œä¸šæ•°æ®åˆ—è¡¨
        """
        # é»˜è®¤åªæœç´¢åç§°
        if search_fields is None:
            search_fields = ["industry_name"]
        
        return query_utils.get_all_records(
            model_class=Industry,
            search=search,
            search_fields=search_fields,
            limit=limit,
            offset=offset
        )


    @staticmethod
    def get_all_ts_codes() -> List[Dict[str, Any]]:
        """è¿”å›å…¨éƒ¨è¡Œä¸šä»£ç ï¼Œç»Ÿä¸€å­—æ®µåä¸º ts_codeã€‚"""
        try:
            # ğŸš€ SQLModelä¼˜åŒ–ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè‡ªåŠ¨ç®¡ç†è¿æ¥
            with db_session_context() as db:
                stmt = select(Industry.industry_code)
                result = db.exec(stmt).all()
                return [{"ts_code": code} for code in result if code]
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢è¡Œä¸šå…¨éƒ¨ ts_code å¤±è´¥: {e}")
            return []

    @staticmethod
    def get_hot_industry_codes() -> List[str]:
        """
        è·å–æ‰€æœ‰æœ‰çƒ­åº¦æ•°æ®çš„è¡Œä¸šä»£ç åˆ—è¡¨ï¼ˆæŒ‰hot_rankæ’åºï¼‰
        
        Returns:
            çƒ­é—¨è¡Œä¸šä»£ç åˆ—è¡¨
        """
        try:
            with db_session_context() as db:
                stmt = select(Industry.industry_code).where(
                    Industry.hot_rank.isnot(None)
                ).order_by(Industry.hot_rank.asc())
                result = db.exec(stmt).all()
                return list(result)
        except Exception as e:
            logger.warning(f"è·å–çƒ­é—¨è¡Œä¸šä»£ç å¤±è´¥: {e}")
            return []

    @staticmethod
    def get_industries_smart(
            filters: Optional[Dict[str, Any]] = None,
            search: Optional[str] = None,
            search_fields: Optional[List[str]] = None,
            sort_by: Optional[str] = None,
            sort_period: str = "daily",
            sort_order: str = "desc",
            limit: Optional[int] = 100,
            offset: Optional[int] = 0,
            trade_date: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢è¡Œä¸šåˆ—è¡¨ï¼šæ ¹æ®æ’åºå­—æ®µç±»å‹é€‰æ‹©æŸ¥è¯¢æ–¹å¼
        - åŸºç¡€è¡¨å­—æ®µï¼šä»åŸºç¡€è¡¨æŸ¥è¯¢
        - Kçº¿å­—æ®µï¼šä»åŸºç¡€è¡¨æŸ¥è¯¢ï¼Œç„¶åä»Kçº¿è¡¨è·å–æœ€æ–°æ•°æ®å¹¶æ’åº

        Args:
            filters: è¿‡æ»¤æ¡ä»¶
            search: æœç´¢å…³é”®è¯
            search_fields: æœç´¢å­—æ®µåˆ—è¡¨
            sort_by: æ’åºå­—æ®µï¼ˆç®€åŒ–åçš„å­—æ®µåï¼Œå¦‚ "pct_chg", "total_mv"ï¼‰
            sort_period: æ’åºå‘¨æœŸï¼ˆdaily/weekly/monthlyï¼‰ï¼Œç”¨äº K çº¿å­—æ®µæŸ¥è¯¢
            sort_order: æ’åºæ–¹å‘ï¼ˆasc/descï¼‰
            limit: åˆ†é¡µé™åˆ¶
            offset: åˆ†é¡µåç§»

        Returns:
            {"data": List[Dict], "total": int}
        """
        try:
            from app.constants.table_types import TableTypes
            return query_utils.get_records_smart(
                table_type=TableTypes.INDUSTRY,
                filters=filters,
                search=search,
                search_fields=search_fields,
                sort_by=sort_by,
                sort_period=sort_period,
                sort_order=sort_order,
                limit=limit,
                offset=offset,
                trade_date=trade_date,
            )
        except Exception as e:
            logger.error(f"get_industries_smart æŸ¥è¯¢å¤±è´¥: {e}")
            return DAOConfig.format_query_result([])

    @staticmethod
    def get_filtered_industry_codes(
            filters: Optional[Dict[str, Any]] = None,
            search: Optional[str] = None,
            search_fields: Optional[List[str]] = None,
            sort_by: Optional[str] = None,
            sort_order: str = "desc",
            sort_period: str = "daily",
            trade_date: Optional[str] = None,
            limit: Optional[int] = None,
    ) -> List[str]:
        """è·å–ç¬¦åˆç­›é€‰æ¡ä»¶çš„è¡Œä¸šä»£ç åˆ—è¡¨ï¼ˆæ”¯æŒæ’åºå’Œæ•°é‡é™åˆ¶ï¼‰ã€‚"""
        try:
            from app.constants.table_types import TableTypes
            result = query_utils.get_records_smart(
                table_type=TableTypes.INDUSTRY,
                filters=filters,
                search=search,
                search_fields=search_fields,
                sort_by=sort_by or "industry_code",
                sort_order=sort_order,
                sort_period=sort_period,
                limit=limit,
                offset=0,
                trade_date=trade_date,
            )
            return [item.get("industry_code") for item in result.get("data", []) if item.get("industry_code")]
        except Exception as e:
            logger.error(f"get_filtered_industry_codes æŸ¥è¯¢å¤±è´¥: {e}")
            return []

    @staticmethod
    def get_industry_stats_aggregated(
        filters: Optional[Dict[str, Any]] = None,
        search: Optional[str] = None,
        search_fields: Optional[List[str]] = None,
        trade_date: Optional[str] = None,
        sort_period: str = "daily",
    ) -> Dict[str, Any]:
        """è·å–å½“å‰ç­›é€‰æ¡ä»¶ä¸‹è¡Œä¸šçš„æ˜ç»†æ•°æ®ã€‚
        
        è¿”å›itemsåˆ—è¡¨ï¼Œsummaryç”±å‰ç«¯ä»itemsè®¡ç®—ã€‚
        """
        # é»˜è®¤ç©ºç»“æœç»“æ„
        empty_payload: Dict[str, Any] = {
            "items": [],
        }

        if not trade_date:
            logger.warning("get_industry_stats_aggregated æœªæä¾› trade_dateï¼Œè¿”å›ç©ºç»Ÿè®¡ç»“æœ")
            return empty_payload
            
        try:
            from datetime import datetime
            target_date = datetime.strptime(trade_date, "%Y%m%d").date()
            year = target_date.year
        except Exception as e:
            logger.warning(f"è§£æ trade_date å¤±è´¥({trade_date}): {e}")
            return empty_payload
        
        # è·å–Kçº¿è¡¨æ¨¡å‹
        kline_model = TableFactory.get_table_model(TableTypes.INDUSTRY, year)
        if kline_model is None:
            logger.warning(f"æœªæ‰¾åˆ°å¹´ä»½ {year} çš„è¡Œä¸šKçº¿è¡¨æ¨¡å‹")
            return empty_payload
        
        try:
            with db_session_context() as db:
                industry_model, _ = TableTypes.get_model_info(TableTypes.INDUSTRY)
                m = kline_model
                
                from sqlalchemy import exists
                
                # æ„å»ºåŸºç¡€è¡¨çš„ç­›é€‰æ¡ä»¶å­æŸ¥è¯¢
                base_exists_subq = select(industry_model.industry_code).where(
                    industry_model.industry_code == m.ts_code
                ).correlate(m)
                
                # åº”ç”¨ç­›é€‰å’Œæœç´¢æ¡ä»¶
                base_exists_subq = IndustryDAO._apply_filter_conditions(
                    base_exists_subq, filters, search, search_fields, industry_model
                )
                
                # æŸ¥è¯¢æ‰€æœ‰è¡Œä¸šæ˜ç»†æ•°æ®
                items_query = select(
                    m.ts_code,
                    industry_model.industry_name,
                    m.close,
                    m.open,
                    m.pct_chg,
                    m.amount,
                    m.float_mv,  # æµé€šå¸‚å€¼ï¼Œç”¨äºæ°”æ³¡å›¾å¤§å°
                ).select_from(m).join(
                    industry_model, m.ts_code == industry_model.industry_code
                ).where(
                    exists(base_exists_subq),
                    m.period == "daily",
                    m.trade_date == target_date
                )
                
                items_result = db.exec(items_query).all()
                items = []
                for row in items_result:
                    open_val = float(row.open) if row.open else 0.0
                    intraday_pct = 0.0
                    if row.open and row.open != 0:
                        intraday_pct = round((row.close - row.open) / row.open * 100, 2)
                    # float_mv å•ä½æ˜¯åƒä¸‡å…ƒï¼Œè½¬æ¢ä¸ºä¸‡å…ƒä»¥ç»Ÿä¸€å•ä½
                    float_mv_wan = float(row.float_mv) * 1000 if row.float_mv else 0.0
                    items.append({
                        "code": row.ts_code,
                        "name": row.industry_name or "",
                        "open": open_val,  # å¼€ç›˜ä»·
                        "close": float(row.close) if row.close else 0.0,
                        "pct_chg": float(row.pct_chg) if row.pct_chg else 0.0,
                        "intraday_pct": intraday_pct,
                        "amount": float(row.amount) if row.amount else 0.0,
                        "circ_mv": float_mv_wan,  # æµé€šå¸‚å€¼(ä¸‡å…ƒ)
                    })
                
                return {
                    "items": items,
                }

        except Exception as e:
            logger.error(f"get_industry_stats_aggregated ç»Ÿè®¡å¤±è´¥: {e}")
            return empty_payload

    @staticmethod
    def get_industry_compare_stats(
        filters: Optional[Dict[str, Any]] = None,
        search: Optional[str] = None,
        search_fields: Optional[List[str]] = None,
        base_date: Optional[str] = None,
        compare_date: Optional[str] = None,
        sort_period: str = "daily",
    ) -> Dict[str, Any]:
        """è®¡ç®—ä¸¤ä¸ªæ—¥æœŸä¹‹é—´çš„è¡Œä¸šæ¶¨è·Œå¯¹æ¯”ç»Ÿè®¡ã€‚"""
        empty_payload: Dict[str, Any] = {
            "base_date": base_date or "",
            "compare_date": compare_date or "",
            "items": [],
        }
        
        if not base_date or not compare_date:
            logger.warning("get_industry_compare_stats ç¼ºå°‘ base_date æˆ– compare_date")
            return empty_payload
        
        try:
            from datetime import datetime
            base_dt = datetime.strptime(base_date, "%Y%m%d").date()
            compare_dt = datetime.strptime(compare_date, "%Y%m%d").date()
            base_year = base_dt.year
            compare_year = compare_dt.year
        except Exception as e:
            logger.warning(f"è§£ææ—¥æœŸå¤±è´¥: {e}")
            return empty_payload
        
        base_kline_model = TableFactory.get_table_model(TableTypes.INDUSTRY, base_year)
        compare_kline_model = TableFactory.get_table_model(TableTypes.INDUSTRY, compare_year)
        
        if base_kline_model is None or compare_kline_model is None:
            logger.warning(f"æœªæ‰¾åˆ°å¹´ä»½ {base_year} æˆ– {compare_year} çš„è¡Œä¸šKçº¿è¡¨æ¨¡å‹")
            return empty_payload
        
        try:
            with db_session_context() as db:
                industry_model, _ = TableTypes.get_model_info(TableTypes.INDUSTRY)
                
                # æ„å»ºç­›é€‰åçš„è¡Œä¸šå­æŸ¥è¯¢
                filtered_industries = select(industry_model.industry_code, industry_model.industry_name)
                filtered_industries = IndustryDAO._apply_filter_conditions(
                    filtered_industries, filters, search, search_fields, industry_model
                )
                filtered_industries_subq = filtered_industries.subquery()
                
                # åŒå¹´ä¼˜åŒ–ï¼šä½¿ç”¨ IN å­æŸ¥è¯¢åˆ©ç”¨å”¯ä¸€ç´¢å¼• (ts_code, period, trade_date)
                if base_year == compare_year:
                    k = base_kline_model
                    
                    # æ„å»º ts_code IN (...) å­æŸ¥è¯¢
                    ts_codes_subq = select(filtered_industries_subq.c.industry_code)
                    
                    # ğŸš€ æŸ¥è¯¢1ï¼šåªæŸ¥è¯¢ Aæ—¥ å’Œ Bæ—¥ ä¸¤å¤©æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
                    price_query = select(
                        k.ts_code,
                        filtered_industries_subq.c.industry_name,
                        func.max(case((k.trade_date == base_dt, k.open))).label("open_a"),
                        func.max(case((k.trade_date == compare_dt, k.close))).label("close_b"),
                        func.max(case((k.trade_date == compare_dt, k.float_mv))).label("float_mv_b"),
                    ).select_from(k).join(
                        filtered_industries_subq, k.ts_code == filtered_industries_subq.c.industry_code
                    ).where(
                        k.ts_code.in_(ts_codes_subq),
                        k.period == sort_period,
                        k.trade_date.in_([base_dt, compare_dt])
                    ).group_by(k.ts_code, filtered_industries_subq.c.industry_name)
                    
                    price_results = db.exec(price_query).all()
                    
                    # ğŸš€ æŸ¥è¯¢2ï¼šåŒºé—´ç´¯è®¡æˆäº¤é¢ï¼ˆä½¿ç”¨KlineAggregatorä¼˜åŒ–ï¼‰
                    from .utils.kline_aggregator import KlineAggregator
                    from .utils.kline_extreme_aggregator import KlineExtremeAggregator
                    amount_map = KlineAggregator.query_cumulative(
                        db_session_context, k, ts_codes_subq, base_dt, compare_dt
                    )
                    
                    # ğŸš€ æŸ¥è¯¢3ï¼šåŒºé—´æç«¯å€¼
                    extreme_map = KlineExtremeAggregator.query_extremes(
                        db_session_context, k, ts_codes_subq, base_dt, compare_dt
                    )
                    
                    items = []
                    for r in price_results:
                        if r.open_a and r.open_a > 0 and r.close_b is not None:
                            open_a = float(r.open_a)
                            close_b = float(r.close_b)
                            pct = (close_b - open_a) / open_a * 100
                            float_mv_wan = float(r.float_mv_b) * 1000 if r.float_mv_b else 0.0
                            
                            extreme = extreme_map.get(r.ts_code, {})
                            high_price = float(extreme.get("high", 0.0))
                            low_price = float(extreme.get("low", 0.0))
                            max_pct = ((high_price - open_a) / open_a * 100) if high_price > 0 else None
                            min_pct = ((low_price - open_a) / open_a * 100) if low_price > 0 else None
                            
                            items.append({
                                "code": r.ts_code,
                                "name": r.industry_name or "",
                                "open": open_a,
                                "close": close_b,
                                "pct_chg": round(pct, 2),
                                "max_pct": round(max_pct, 2) if max_pct is not None else None,
                                "min_pct": round(min_pct, 2) if min_pct is not None else None,
                                "high_price": high_price if high_price > 0 else None,
                                "low_price": low_price if low_price > 0 else None,
                                "amount": amount_map.get(r.ts_code, 0.0),
                                "circ_mv": float_mv_wan,
                            })
                    
                    return {
                        "base_date": base_date,
                        "compare_date": compare_date,
                        "items": items,
                    }
                
                # ğŸš€ è·¨å¹´æŸ¥è¯¢ï¼šåˆ†ç¦»æŸ¥è¯¢ä¼˜åŒ–
                k_a = base_kline_model
                k_b = compare_kline_model
                
                # æ„å»º ts_code IN (...) å­æŸ¥è¯¢
                ts_codes_subq = select(filtered_industries_subq.c.industry_code)
                
                # ğŸš€ æŸ¥è¯¢1ï¼šåªæŸ¥è¯¢ Aæ—¥ å’Œ Bæ—¥ çš„ä»·æ ¼æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
                price_a_query = select(
                    k_a.ts_code.label("ts_code"),
                    k_a.open.label("open_a"),
                ).select_from(k_a).join(
                    filtered_industries_subq, k_a.ts_code == filtered_industries_subq.c.industry_code
                ).where(
                    k_a.ts_code.in_(ts_codes_subq),
                    k_a.period == sort_period,
                    k_a.trade_date == base_dt
                )
                price_a_results = db.exec(price_a_query).all()
                price_a_map = {r.ts_code: float(r.open_a) if r.open_a else None for r in price_a_results}
                
                price_b_query = select(
                    k_b.ts_code.label("ts_code"),
                    filtered_industries_subq.c.industry_name,
                    k_b.close.label("close_b"),
                    k_b.float_mv.label("float_mv_b"),
                ).select_from(k_b).join(
                    filtered_industries_subq, k_b.ts_code == filtered_industries_subq.c.industry_code
                ).where(
                    k_b.ts_code.in_(ts_codes_subq),
                    k_b.period == sort_period,
                    k_b.trade_date == compare_dt
                )
                price_b_results = db.exec(price_b_query).all()
                
                # ğŸš€ æŸ¥è¯¢2ï¼šåŒºé—´ç´¯è®¡æˆäº¤é¢ï¼ˆä½¿ç”¨KlineAggregatorä¼˜åŒ– - è·¨å¹´ï¼‰
                from datetime import date
                from .utils.kline_aggregator import KlineAggregator
                from .utils.kline_extreme_aggregator import KlineExtremeAggregator
                
                a_year_end = date(base_year, 12, 31)
                b_year_start = date(compare_year, 1, 1)
                
                amounts_a = KlineAggregator.query_cumulative(
                    db_session_context, k_a, ts_codes_subq, base_dt, a_year_end
                )
                amounts_b = KlineAggregator.query_cumulative(
                    db_session_context, k_b, ts_codes_subq, b_year_start, compare_dt
                )
                
                # åˆå¹¶Aå¹´å’ŒBå¹´æˆäº¤é¢
                amount_map = {}
                for code, amt in amounts_a.items():
                    amount_map[code] = amt
                for code, amt in amounts_b.items():
                    amount_map[code] = amount_map.get(code, 0.0) + amt
                
                # ğŸš€ æŸ¥è¯¢3ï¼šåŒºé—´æç«¯å€¼ï¼ˆè·¨å¹´ï¼‰
                extremes_a = KlineExtremeAggregator.query_extremes(
                    db_session_context, k_a, ts_codes_subq, base_dt, a_year_end
                )
                extremes_b = KlineExtremeAggregator.query_extremes(
                    db_session_context, k_b, ts_codes_subq, b_year_start, compare_dt
                )
                
                extreme_map = {}
                for code, ext in extremes_a.items():
                    extreme_map[code] = ext.copy()
                for code, ext in extremes_b.items():
                    if code in extreme_map:
                        extreme_map[code]["high"] = max(extreme_map[code].get("high", 0), ext.get("high", 0))
                        extreme_map[code]["low"] = min(extreme_map[code].get("low", float('inf')), ext.get("low", float('inf')))
                    else:
                        extreme_map[code] = ext.copy()
                
                # åœ¨Pythonå±‚åˆå¹¶ç»“æœå¹¶è®¡ç®—æ¶¨è·Œå¹…
                items = []
                for r in price_b_results:
                    open_a = price_a_map.get(r.ts_code)
                    close_b = float(r.close_b) if r.close_b is not None else None
                    if open_a and open_a > 0 and close_b is not None:
                        pct = (close_b - open_a) / open_a * 100
                        float_mv_wan = float(r.float_mv_b) * 1000 if r.float_mv_b else 0.0
                        
                        extreme = extreme_map.get(r.ts_code, {})
                        high_price = float(extreme.get("high", 0.0))
                        low_price = float(extreme.get("low", 0.0))
                        max_pct = ((high_price - open_a) / open_a * 100) if high_price > 0 else None
                        min_pct = ((low_price - open_a) / open_a * 100) if low_price > 0 else None
                        
                        items.append({
                            "code": r.ts_code,
                            "name": r.industry_name or "",
                            "open": open_a,
                            "close": close_b,
                            "pct_chg": round(pct, 2),
                            "max_pct": round(max_pct, 2) if max_pct is not None else None,
                            "min_pct": round(min_pct, 2) if min_pct is not None else None,
                            "high_price": high_price if high_price > 0 else None,
                            "low_price": low_price if low_price > 0 else None,
                            "amount": amount_map.get(r.ts_code, 0.0),
                            "circ_mv": float_mv_wan,
                        })
                
                return {
                    "base_date": base_date,
                    "compare_date": compare_date,
                    "items": items,
                }
                
        except Exception as e:
            logger.error(f"get_industry_compare_stats ç»Ÿè®¡å¤±è´¥: {e}")
            return empty_payload

    # ==================== çƒ­åº¦æ•°æ®åŒæ­¥ ====================

    @staticmethod
    def sync_hot_data(
            hot_data_list: List[Dict[str, Any]],
            trade_date: str,
    ) -> Dict[str, Any]:
        """
        åŒæ­¥è¡Œä¸šçƒ­åº¦æ•°æ®åˆ°åŸºç¡€è¡¨ï¼ˆindustriesè¡¨ï¼‰
        
        Args:
            hot_data_list: çƒ­åº¦æ•°æ®åˆ—è¡¨
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å’Œå˜æ›´é›†
        """

        if not hot_data_list:
            return DAOConfig.format_upsert_result({
                "inserted": 0,
                "updated": 0,
                "total": 0
            })

        try:
            # å‡†å¤‡æ‰¹é‡æ›´æ–°æ•°æ®
            update_data = []

            for hot_item in hot_data_list:
                industry_code = hot_item.get("industry_code")
                if not industry_code:
                    continue

                # å‡†å¤‡çƒ­åº¦æ•°æ®
                hot_metrics = {
                    'industry_code': industry_code,
                    'hot_rank': hot_item.get("hot_rank"),
                    'hot_score': hot_item.get("hot_score"),
                    'hot_date': trade_date,
                    'hot_concept': hot_item.get("hot_concept"),
                    'hot_rank_reason': hot_item.get("hot_rank_reason"),
                }
                update_data.append(hot_metrics)

            # æ‰¹é‡æ›´æ–°åŸºç¡€è¡¨çš„çƒ­åº¦å­—æ®µï¼ˆä»…æ›´æ–°å·²å­˜åœ¨çš„è®°å½•ï¼Œä¸æ’å…¥æ–°è®°å½•ï¼‰
            stats = IndustryDAO._bulk_update_hot_data(update_data)
            
            # ç›´æ¥è¿”å›statsï¼Œå› ä¸º_bulk_update_hot_dataå·²ç»è¿”å›æ ‡å‡†æ ¼å¼
            return stats

        except Exception as e:
            logger.error(f"åŒæ­¥è¡Œä¸šçƒ­åº¦æ•°æ®å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›å¤±è´¥ç»“æœ
            return DAOConfig.format_upsert_result({
                "inserted": 0,
                "updated": 0,
                "total": len(hot_data_list) if hot_data_list else 0
            })
    
    @staticmethod
    def _bulk_update_hot_data(update_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        æ‰¹é‡æ›´æ–°è¡Œä¸šçƒ­åº¦æ•°æ®ï¼ˆåªæ›´æ–°ï¼Œä¸æ’å…¥ï¼‰
        """
        if not update_data:
            return DAOConfig.format_upsert_result({
                "inserted": 0,
                "updated": 0,
                "total": 0
            })
        
        try:
            # ğŸš€ é‡å¤§æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨æ‰¹é‡å‚æ•°åŒ–æŸ¥è¯¢ï¼Œé¿å…å¾ªç¯
            from sqlmodel import text
            
            with db_session_context() as db:
                # è¿‡æ»¤æ‰æ— æ•ˆçš„industry_code
                valid_data = [data for data in update_data if data.get('industry_code')]
                
                if not valid_data:
                    return DAOConfig.format_upsert_result({
                        "inserted": 0, "updated": 0, "total": 0
                    })
                
                # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨å‚æ•°åŒ–SQLå’Œexecutemanyè¿›è¡Œæ‰¹é‡æ›´æ–°
                sql = text("""
                    UPDATE industries 
                    SET hot_rank = :hot_rank,
                        hot_score = :hot_score,
                        hot_date = :hot_date,
                        hot_concept = :hot_concept,
                        hot_rank_reason = :hot_rank_reason,
                        updated_at = NOW()
                    WHERE industry_code = :industry_code
                """)
                
                # ä½¿ç”¨executemanyæ‰¹é‡æ‰§è¡Œ
                result = db.connection().execute(sql, valid_data)
                updated_count = result.rowcount
                
                db.commit()
                return DAOConfig.format_upsert_result({
                    "inserted": 0,
                    "updated": updated_count,
                    "total": len(valid_data)
                })
                
        except Exception as e:
            logger.error(f"æ‰¹é‡æ›´æ–°è¡Œä¸šçƒ­åº¦æ•°æ®å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›å¤±è´¥ç»“æœ
            return DAOConfig.format_upsert_result({
                "inserted": 0,
                "updated": 0,
                "total": len(update_data)
            })


# åˆ›å»ºå…¨å±€å®ä¾‹
industry_dao = IndustryDAO()
