"""
ç¼“å­˜æœåŠ¡ - ç”¨äºä¼˜åŒ–Kçº¿æ•°æ®åŒæ­¥æ€§èƒ½
"""

import json
import os
from datetime import datetime, date
from decimal import Decimal
from typing import Optional, Dict, Any, List

import redis
from loguru import logger

from config.config import settings


class DateTimeEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†datetimeå’ŒDecimalç±»å‹"""

    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        if isinstance(obj, Decimal):
            # å°† Decimal å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ˆæˆ–ä½¿ç”¨ str(obj) å¦‚éœ€ä¿æŒç²¾åº¦ï¼‰
            try:
                return float(obj)
            except Exception:
                return str(obj)
        return super().default(obj)


class CacheService:
    """ç¼“å­˜æœåŠ¡ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        self.redis_client = None
        self._memory_cache = {}
        self._cache_enabled = self._is_cache_enabled()
        self._init_redis()

    def _is_cache_enabled(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨"""
        # æ”¯æŒç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶ä¸¤ç§æ–¹å¼
        env_enabled = os.getenv('FEATURE_CACHE_ENABLED', '').lower()
        if env_enabled in ('true', '1', 'yes', 'on'):
            return True
        elif env_enabled in ('false', '0', 'no', 'off'):
            return False

        # ä»é…ç½®æ–‡ä»¶è¯»å–
        return getattr(settings, 'FEATURE_CACHE_ENABLED', True)

    def is_cache_enabled(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨"""
        return self._cache_enabled

    def enable_cache(self):
        """å¯ç”¨ç¼“å­˜"""
        self._cache_enabled = True
        logger.info("ç¼“å­˜å·²å¯ç”¨")

    def disable_cache(self):
        """ç¦ç”¨ç¼“å­˜"""
        self._cache_enabled = False
        logger.info("ç¼“å­˜å·²ç¦ç”¨")

    def _init_redis(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            # å°è¯•è¿æ¥Redis
            if hasattr(settings, "REDIS_URL") and settings.REDIS_URL:
                self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            else:
                self.redis_client = redis.Redis(
                    host=getattr(settings, "REDIS_HOST", "localhost"),
                    port=getattr(settings, "REDIS_PORT", 6379),
                    db=getattr(settings, "REDIS_DB", 0),
                    password=getattr(settings, "REDIS_PASSWORD", None),
                    decode_responses=True,
                )

            # æµ‹è¯•è¿æ¥
            self.redis_client.ping()
            logger.info("Redisç¼“å­˜æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.warning(f"Redisè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…å­˜ç¼“å­˜: {e}")
            self.redis_client = None
            # ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            self._memory_cache = {}

    # ========== é€šç”¨ JSON ç¼“å­˜è¯»å†™ï¼ˆæ—  TTLï¼‰ ==========
    def get_json(self, key: str) -> Optional[Any]:
        if not self._cache_enabled:
            return None

        try:
            if self.redis_client:
                raw = self.redis_client.get(key)
                result = json.loads(raw) if raw else None
                return result
            else:
                result = self._memory_cache.get(key)
                return result
        except Exception as e:
            logger.warning(f"get_json å¤±è´¥ {key}: {e}")
            return None

    def set_json(self, key: str, value: Any, ttl_seconds: int = 86400) -> None:
        if not self._cache_enabled:
            return

        try:
            data = json.dumps(value, cls=DateTimeEncoder)
            if self.redis_client:
                if ttl_seconds > 0:
                    # è®¾ç½®å¸¦TTLçš„é”®
                    self.redis_client.setex(key, ttl_seconds, data)
                else:
                    # TTLä¸º0è¡¨ç¤ºæ°¸ä¸è¿‡æœŸï¼Œä½¿ç”¨setå‘½ä»¤
                    self.redis_client.set(key, data)
            else:
                self._memory_cache[key] = value
        except Exception as e:
            logger.warning(f"set_json å¤±è´¥ {key}: {e}")
            pass

    def exists(self, key: str) -> bool:
        """æ£€æŸ¥keyæ˜¯å¦å­˜åœ¨"""
        if not self._cache_enabled:
            return False

        try:
            if self.redis_client:
                return bool(self.redis_client.exists(key))
            else:
                return key in self._memory_cache
        except Exception as e:
            logger.warning(f"exists æ£€æŸ¥å¤±è´¥ {key}: {e}")
            return False

    def set_nx(self, key: str, value: Any, ttl_seconds: int = 86400) -> bool:
        """åŸå­æ€§åœ°è®¾ç½®keyï¼ˆä»…å½“keyä¸å­˜åœ¨æ—¶ï¼‰
        
        ä½¿ç”¨Redisçš„SET NX EXåŸå­å‘½ä»¤ï¼Œè§£å†³å¹¶å‘ç¯å¢ƒä¸‹çš„ç«æ€æ¡ä»¶é—®é¢˜ã€‚
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl_seconds: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            True: è®¾ç½®æˆåŠŸï¼ˆkeyä¹‹å‰ä¸å­˜åœ¨ï¼‰
            False: è®¾ç½®å¤±è´¥ï¼ˆkeyå·²å­˜åœ¨æˆ–ç¼“å­˜ç¦ç”¨ï¼‰
        """
        if not self._cache_enabled or not self.redis_client:
            return False

        try:
            data = json.dumps(value, cls=DateTimeEncoder)
            result = self.redis_client.set(key, data, nx=True, ex=ttl_seconds)
            return result is True
        except Exception as e:
            logger.warning(f"set_nx å¤±è´¥ {key}: {e}")
            return False

    def delete(self, key: str) -> int:
        """åˆ é™¤å•ä¸ª keyï¼Œè¿”å›åˆ é™¤æ•°é‡ã€‚"""
        if not self._cache_enabled:
            return 0

        try:
            if self.redis_client:
                # redis-py åœ¨ key ä¸å­˜åœ¨æ—¶è¿”å› 0
                deleted = self.redis_client.delete(key)
                return int(deleted or 0)
            else:
                existed = key in self._memory_cache
                self._memory_cache.pop(key, None)
                return 1 if existed else 0
        except Exception as e:
            logger.warning(f"delete å¤±è´¥ {key}: {e}")
            return 0

    def delete_keys_by_patterns(self, patterns: List[str]) -> int:
        """æŒ‰å¤šä¸ªæ¨¡å¼åˆ é™¤ï¼Œè¿”å›åˆ é™¤ key æ•°é‡ï¼ˆRedis ä¸‹ä¸ºä¼°è®¡å€¼ï¼‰ã€‚"""
        if not self._cache_enabled:
            return 0

        deleted = 0
        try:
            if self.redis_client:
                for pattern in patterns:
                    # ä½¿ç”¨ SCAN + pipeline åˆ†æ‰¹åˆ é™¤ï¼Œé¿å… KEYS é˜»å¡
                    cursor = 0
                    while True:
                        cursor, keys = self.redis_client.scan(cursor=cursor, match=pattern, count=1000)
                        if keys:
                            pipe = self.redis_client.pipeline()
                            for k in keys:
                                pipe.delete(k)
                            pipe.execute()
                            deleted += len(keys)
                        if cursor == 0:
                            break
            else:
                to_delete: List[str] = []
                for pattern in patterns:
                    frag = pattern.replace("*", "")
                    to_delete.extend([k for k in list(self._memory_cache.keys()) if frag in k])
                for k in set(to_delete):
                    self._memory_cache.pop(k, None)
                deleted = len(set(to_delete))

        except Exception as e:
            logger.warning(f"delete_keys_by_patterns å¤±è´¥: {e}")
            pass
        return deleted

    # ========== é«˜å±‚ Key ç”Ÿæˆï¼ˆCacheKeysï¼‰ä¸å¤±æ•ˆ API ==========
    class Keys:
        NS = ""

        @classmethod
        def list_pattern(cls, entity: str) -> str:
            return f"{entity}:list*"

        @classmethod
        def detail(cls, entity: str, code: str) -> str:
            return f"{entity}:detail:{code}"

        @classmethod
        def detail_pattern(cls, entity: str) -> str:
            return f"{entity}:detail:*"

        @classmethod
        def members(cls, entity: str, owner: str) -> str:
            return f"{entity}:members:{owner}"

        @classmethod
        def members_pattern(cls, entity: str) -> str:
            return f"{entity}:members:*"

        @classmethod
        def all_ts_codes_key(cls) -> str:
            return "stocks:all_ts_codes:v1"

        @classmethod
        def all_bond_codes_key(cls) -> str:
            return "bonds:all_ts_codes:v1"

        @classmethod
        def all_concept_codes_key(cls) -> str:
            return "concepts:all_ts_codes:v1"

        @classmethod
        def all_industry_codes_key(cls) -> str:
            return "industries:all_ts_codes:v1"
        
        @classmethod
        def kline_latest_dates_key(cls, table_type: str, codes_hash: str, periods_hash: str) -> str:
            """Kçº¿æœ€æ–°æ—¥æœŸç¼“å­˜é”®"""
            return f"klines:latest_dates:{table_type}:{codes_hash}:{periods_hash}"
        
        @classmethod
        def kline_latest_dates_pattern(cls, table_type: str = "*") -> str:
            """Kçº¿æœ€æ–°æ—¥æœŸç¼“å­˜æ¨¡å¼"""
            return f"klines:latest_dates:{table_type}:*"

    def invalidate_stock_cache(self) -> int:
        patterns = [
            self.Keys.list_pattern("stocks"),
            self.Keys.detail_pattern("stocks"),
        ]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_bond_cache(self) -> int:
        patterns = [
            self.Keys.list_pattern("bonds"),
            self.Keys.detail_pattern("bonds"),
            "bonds:mappings:*",  # ç»Ÿä¸€åŒå‘æ˜ å°„ç¼“å­˜ï¼ˆå¯è½¬å€º-è‚¡ç¥¨ï¼‰
        ]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_concept_cache(self) -> int:
        patterns = [
            self.Keys.list_pattern("concepts"),
            self.Keys.detail_pattern("concepts"),
            self.Keys.members_pattern("concepts"),
            "concepts:members_of_stock:*",  # é€æ¡ç¼“å­˜ï¼šæ¯ä¸ªè‚¡ç¥¨çš„æ¦‚å¿µåˆ—è¡¨
            "concepts:all_ts_codes:*",  # å…¨éƒ¨æ¦‚å¿µä»£ç ç¼“å­˜
        ]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_industry_cache(self) -> int:
        patterns = [
            self.Keys.list_pattern("industries"),
            self.Keys.detail_pattern("industries"),
            self.Keys.members_pattern("industries"),
            "industries:members_of_stock:*",  # é€æ¡ç¼“å­˜ï¼šæ¯ä¸ªè‚¡ç¥¨çš„è¡Œä¸šåˆ—è¡¨
            "industries:all_ts_codes:*",  # å…¨éƒ¨è¡Œä¸šä»£ç ç¼“å­˜
        ]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_bond_call_cache(self) -> int:
        """ç²—ç²’åº¦å¤±æ•ˆï¼šæŒ‰å‰ç¼€æ¸…ç†å¯è½¬å€ºèµå›ä¿¡æ¯ç¼“å­˜ï¼ˆåˆ—è¡¨ä¸è¯¦æƒ…ï¼‰ã€‚"""
        patterns = [
            self.Keys.list_pattern("bond_calls"),
            self.Keys.detail_pattern("bond_calls"),
        ]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_all_stock_codes(self) -> int:
        """åˆ é™¤å€™é€‰è‚¡ç¥¨é›†åˆç¼“å­˜ã€‚"""
        return self.delete_keys_by_patterns([self.Keys.all_ts_codes_key()])

    def invalidate_all_bond_codes(self) -> int:
        """åˆ é™¤å€™é€‰å¯è½¬å€ºé›†åˆç¼“å­˜ã€‚"""
        return self.delete_keys_by_patterns([self.Keys.all_bond_codes_key()])

    def invalidate_all_concept_codes(self) -> int:
        """åˆ é™¤å€™é€‰æ¦‚å¿µé›†åˆç¼“å­˜ã€‚"""
        return self.delete_keys_by_patterns([self.Keys.all_concept_codes_key()])

    def invalidate_all_industry_codes(self) -> int:
        """åˆ é™¤å€™é€‰è¡Œä¸šé›†åˆç¼“å­˜ã€‚"""
        return self.delete_keys_by_patterns([self.Keys.all_industry_codes_key()])

    # ========== Kçº¿ç¼“å­˜å¤±æ•ˆ ==========
    def _invalidate_klines_for_codes(self, entity_type: str, period: str, ts_codes: List[str]) -> int:
        """
        é€šç”¨æ–¹æ³•ï¼šæŒ‰ä»£ç +å‘¨æœŸåˆ é™¤Kçº¿ç¼“å­˜
        ğŸš€ ä»£ç é‡æ„ï¼šæ¶ˆé™¤é‡å¤ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§
        
        Args:
            entity_type: å®ä½“ç±»å‹ (stock/bond/concept/industry)
            period: å‘¨æœŸ
            ts_codes: ä»£ç åˆ—è¡¨
            
        Returns:
            åˆ é™¤çš„ç¼“å­˜é”®æ•°é‡
        """
        codes = list(set(ts_codes or []))
        if not codes:
            return 0
        patterns = [f"klines:{entity_type}:{period}:{code}" for code in codes]
        return self.delete_keys_by_patterns(patterns)

    def invalidate_stock_klines_for_codes(self, period: str, ts_codes: List[str]) -> int:
        """ç²¾ç»†åŒ–å¤±æ•ˆï¼šæŒ‰ä»£ç +å‘¨æœŸåˆ é™¤è‚¡ç¥¨Kçº¿ç¼“å­˜ã€‚"""
        return self._invalidate_klines_for_codes("stock", period, ts_codes)

    def invalidate_bond_klines_for_codes(self, period: str, ts_codes: List[str]) -> int:
        """ç²¾ç»†åŒ–å¤±æ•ˆï¼šæŒ‰ä»£ç +å‘¨æœŸåˆ é™¤å¯è½¬å€ºKçº¿ç¼“å­˜ã€‚"""
        return self._invalidate_klines_for_codes("bond", period, ts_codes)

    def invalidate_concept_klines_for_codes(self, period: str, ts_codes: List[str]) -> int:
        """ç²¾ç»†åŒ–å¤±æ•ˆï¼šæŒ‰ä»£ç +å‘¨æœŸåˆ é™¤æ¦‚å¿µKçº¿ç¼“å­˜ã€‚"""
        return self._invalidate_klines_for_codes("concept", period, ts_codes)

    def invalidate_industry_klines_for_codes(self, period: str, ts_codes: List[str]) -> int:
        """ç²¾ç»†åŒ–å¤±æ•ˆï¼šæŒ‰ä»£ç +å‘¨æœŸåˆ é™¤è¡Œä¸šKçº¿ç¼“å­˜ã€‚"""
        return self._invalidate_klines_for_codes("industry", period, ts_codes)
    
    def invalidate_kline_latest_dates(self, table_type: str = None) -> int:
        """å¤±æ•ˆKçº¿æœ€æ–°æ—¥æœŸç¼“å­˜"""
        if table_type:
            patterns = [self.Keys.kline_latest_dates_pattern(table_type)]
        else:
            patterns = [self.Keys.kline_latest_dates_pattern()]
        return self.delete_keys_by_patterns(patterns)


# å…¨å±€ç¼“å­˜æœåŠ¡å®ä¾‹
cache_service = CacheService()

# ===== æœåŠ¡å±‚é€šç”¨è¯»ç©¿é€ç¼“å­˜è£…é¥°å™¨ï¼ˆä»…æœåŠ¡å±‚ä½¿ç”¨ï¼‰ =====
from functools import wraps as _wraps
from typing import Callable as _Callable


def service_cached(prefix: str, key_fn: _Callable[..., str], ttl_seconds: int = 86400):
    """
    æœåŠ¡å±‚è¯»ç©¿é€ç¼“å­˜è£…é¥°å™¨ã€‚

    Args:
        prefix: ç¼“å­˜é”®å‰ç¼€ï¼ˆä¾‹å¦‚ "stocks:detail"ã€"concepts:members_of_stock"ï¼‰
        key_fn: ä»å‡½æ•°å‚æ•°ç”Ÿæˆå­é”®çš„å‡½æ•°ï¼Œè¿”å›å­—ç¬¦ä¸²ï¼Œå¦‚ ts_code/period ç­‰
        ttl_seconds: ç¼“å­˜ TTLï¼Œé»˜è®¤ 86400 ç§’
    """

    def decorator(func):
        @_wraps(func)
        def wrapper(*args, **kwargs):
            # ç¼“å­˜å¼€å…³
            if not cache_service.is_cache_enabled():
                return func(*args, **kwargs)
            try:
                suffix = key_fn(*args, **kwargs)
                # è‹¥è¿”å›ç©ºåç¼€ï¼Œåˆ™è§†ä¸ºä¸å‚ä¸ç¼“å­˜ï¼ˆå…è®¸è°ƒç”¨æ–¹é€šè¿‡è¿”å›ç©ºå­—ç¬¦ä¸²æ¥æ˜¾å¼è·³è¿‡ç¼“å­˜ï¼‰
                if not suffix:
                    return func(*args, **kwargs)
                # å½“ prefix ä¸ºç©ºæ—¶ä¸åŠ å†’å·åˆ†éš”ç¬¦
                key = f"{prefix}:{suffix}" if prefix else suffix
                cached = cache_service.get_json(key)
                if cached is not None:
                    # å½“ç¼“å­˜å­˜åœ¨ä½†ä¸ºç©ºé›†åˆ/å¯¹è±¡æ—¶ï¼Œå°è¯•å›æºä¸€æ¬¡ä»¥ä¿®å¤â€œç©ºç¼“å­˜å¡æ­»â€é—®é¢˜
                    if (isinstance(cached, list) and len(cached) == 0) or (
                            isinstance(cached, dict) and len(cached) == 0):
                        refreshed = func(*args, **kwargs)
                        if refreshed is not None and not (isinstance(refreshed, (list, dict)) and len(refreshed) == 0):
                            cache_service.set_json(key, refreshed, ttl_seconds)
                            return refreshed
                        return cached
                    return cached
                result = func(*args, **kwargs)
                if result is not None:
                    cache_service.set_json(key, result, ttl_seconds)
                return result
            except Exception:
                # ä»»æ„å¼‚å¸¸ç›´æ¥å›æº
                return func(*args, **kwargs)

        return wrapper

    return decorator
